'''
Parameter discovery with PINN.

Poisson's equation: (d^2/dx^2 + d^2/dy^2) \phi = \rho(x, y)
\rho(x, y) = 1.5 for all x, y, but we don't know it.

Domain: x \in [-1, 1], y \in [-1, 1],
Boundary conditions: \phi(x, -1) = cos(pi * x / 2), \phi(x, 1) = \phi(\pm 1, y) = 0

5000 data points are generated by the solver of Poisson's equation with PINN.

The losses for parameter discovery are:
    loss_f = (d^2/dx^2 + d^2/dy^2) \phi - \rho(x, y)
    loss_data = \phi(x, y) - \phi_data(x, y)
'''

import math
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from used_funcs import *

path = ""
plt.figure(figsize=(16, 6))
plt.get_current_fig_manager().window.wm_geometry('+10+10')

# load the data
data = torch.load(path + 'data.pth')
dataset = torch.utils.data.TensorDataset(data[:, :2], data[:, 2:])
dataloader = torch.utils.data.DataLoader(dataset, batch_size=512, shuffle=True)

# the model for parameter discovery, where rho is a new parameter
class PINN_discovery(PINN):
    def __init__(self, inputs=2, outputs=1, hidden_layers=100) -> None:
        super(PINN_discovery, self).__init__(inputs, outputs, hidden_layers)
        self.rho = nn.Parameter(torch.tensor(1.0), requires_grad=True)
    def forward(self, xy):
        layer = self.input_layer(xy)
        layer = self.block(layer) + layer
        phi = self.output_layer(layer)
        return phi
    
model = PINN_discovery(hidden_layers=100)
optimizer = optim.Adam(model.parameters(), lr=0.001)

loss_list = []
rho_list = []
for epoch in range(2001):
    loss_epoch = []
    for batch_r, batch_phi in dataloader:
        phi = model(batch_r)
        loss_data = (phi - batch_phi).pow(2).mean()
    
        # Poison's equation
        batch_r.requires_grad_(True)
        batch_phi_r = torch.autograd.grad(phi, batch_r, create_graph=True, grad_outputs=torch.ones_like(phi))[0]
        batch_phi_xx = torch.autograd.grad(batch_phi_r[:, 0], batch_r, create_graph=True, grad_outputs=torch.ones_like(batch_phi_r[:, 0]))[0][:, 0].reshape(-1, 1)
        batch_phi_yy = torch.autograd.grad(batch_phi_r[:, 1], batch_r, create_graph=True, grad_outputs=torch.ones_like(batch_phi_r[:, 1]))[0][:, 1].reshape(-1, 1)
        batch_f = batch_phi_xx + batch_phi_yy + model.rho
        loss_f = batch_f.pow(2).mean()

        # total loss
        loss = loss_f + loss_data
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        loss_epoch.append(loss.item())
    
    loss_list.append(sum(loss_epoch) / len(loss_epoch))
    rho_list.append(model.rho.item())
    if epoch % 10 == 0:
        print('epoch: {}, loss: {:.6f}, rho: {:.4f}'.format(epoch, loss_list[-1], model.rho.item()))
        plot_results(model, loss_list, rho_list, plot=False, save=True, save_path=path + 'results_discovery.png')
        



